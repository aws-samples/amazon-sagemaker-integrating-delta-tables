{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c749391e-700f-40e9-a78e-7713fa42d353",
   "metadata": {
    "tags": []
   },
   "source": [
    "# From Delta Lake to Amazon SageMaker\n",
    "\n",
    "[Delta Lake](https://delta.io/) is a common open-source framework used for storing data in Lakehouse architectures.\n",
    "\n",
    "In this sample we demonstrate how to integrate Delta Tables with Amazon SageMaker for performing data exploration, ingestion, processing, training, and hosting for Machine Learning.\n",
    "\n",
    "---\n",
    "\n",
    "## 2 - Feature Engineering and Ingestion\n",
    "\n",
    "***Use Kernel \"Data Science 3.0 (Python 3)\" for running this notebook***\n",
    "\n",
    "In this notebook, we will ingest data from our Delta Tables, perform some transformations on it via code using **SageMaker Processing**, and ingesting the resulting features into **SageMaker Feature Store**. For this purpose we will:\n",
    "* Create a SageMaker Feature Store Feature Group, both offline and online\n",
    "* Prepare a processing script for our feature engineering, including the configuration for connecting to our Delta Table\n",
    "* Run a SageMaker Processing job pointing towards our sample Delta Table profile file URL. It will include the code for the transformations and ingesting the resulting features into our Feature Group\n",
    "\n",
    "<center><img src=\"../images/DeltaLake_to_SageMaker_2.png\" width=\"50%\"></center>\n",
    "\n",
    "Note the transformations to the data can also be performed with other services in AWS, e.g. for low-code/no-code processing you can rely on **SageMaker Data Wrangler**, as it currently supports direct connections towards Delta Lakes via JDBC for data exploration, analysis, and feature engineering. You can check more details about this method in this blog post:\n",
    "\n",
    "https://aws.amazon.com/blogs/machine-learning/prepare-data-from-databricks-for-machine-learning-using-amazon-sagemaker-data-wrangler/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec14d92-5184-4ec2-9506-f5eed246b11a",
   "metadata": {},
   "source": [
    "### Processing data from Delta Lake with SageMaker Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c011736-951c-4478-8272-7cb956e7cf43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "import os\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# S3 bucket for saving processing job outputs\n",
    "sm_session = sagemaker.Session()\n",
    "bucket = sm_session.default_bucket()\n",
    "region = sm_session.boto_region_name\n",
    "\n",
    "# Delta Sharing profile file location - Replace these with your own if you want to customize this example\n",
    "table = f's3a://{bucket}/delta_to_sagemaker/delta_format/'\n",
    "output_path = f's3://{bucket}/delta_to_sagemaker/processing_output/'\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3c5810-354d-4b9e-9f2b-5b63a708920f",
   "metadata": {},
   "source": [
    "We will start by creating a SageMaker Feature Store Feature Group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88c561a6-9ec9-44d8-9373-650fff270a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowID              int64\n",
      "timestamp         object\n",
      "userID            string\n",
      "placeID           string\n",
      "rating_overall     int64\n",
      "rating_food        int64\n",
      "rating_service     int64\n",
      "EventTime         string\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "current_time_sec = int(round(time.time()))\n",
    "\n",
    "features = pd.read_csv('../data/fact_rating_synthetic.csv')\n",
    "features.drop(['ratingID'], axis=1, inplace=True)\n",
    "features.columns=['rowID', 'timestamp', 'userID', 'placeID', 'rating_overall', 'rating_food', 'rating_service']\n",
    "features = features.astype({'rowID': 'int'})\n",
    "features = features.astype({'userID': 'string'})\n",
    "features = features.astype({'placeID': 'string'})\n",
    "features[\"EventTime\"] = pd.Series([current_time_sec] * len(features), dtype=\"string\")\n",
    "\n",
    "print(features.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3a231c6-b1d9-46ef-b941-d03c0762e6de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FeatureDefinition(feature_name='rowID', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='timestamp', feature_type=<FeatureTypeEnum.STRING: 'String'>),\n",
       " FeatureDefinition(feature_name='userID', feature_type=<FeatureTypeEnum.STRING: 'String'>),\n",
       " FeatureDefinition(feature_name='placeID', feature_type=<FeatureTypeEnum.STRING: 'String'>),\n",
       " FeatureDefinition(feature_name='rating_overall', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='rating_food', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='rating_service', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='EventTime', feature_type=<FeatureTypeEnum.STRING: 'String'>)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "feature_group_name = 'rating-fg'\n",
    "\n",
    "feature_group = FeatureGroup(\n",
    "    name=feature_group_name,\n",
    "    sagemaker_session=sm_session,\n",
    ")\n",
    "\n",
    "feature_group.load_feature_definitions(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccb3e30-0e9f-415f-962c-e6be7b9f239e",
   "metadata": {},
   "source": [
    "As we create the Feature Group in the Feature Store, note we setup the format to use Apache Iceberg increased performance and efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7196124-6352-4d67-8ef7-d82a9fcc7fe6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:eu-west-1:889960878219:feature-group/rating-fg\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.feature_store.inputs import TableFormatEnum\n",
    "\n",
    "fg = feature_group.create(\n",
    "    s3_uri=f's3://{bucket}/delta_to_sagemaker/',\n",
    "    role_arn=role,\n",
    "    record_identifier_name='rowID',\n",
    "    event_time_feature_name='EventTime',\n",
    "    enable_online_store=True,\n",
    "    table_format=TableFormatEnum.ICEBERG\n",
    ")\n",
    "\n",
    "feature_group_arn = fg['FeatureGroupArn']\n",
    "print(feature_group_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56444e84-5d6b-4f56-981b-6e6fc10b1743",
   "metadata": {},
   "source": [
    "To confirm that your FeatureGroup has been created we use `DescribeFeatureGroup` and `ListFeatureGroups` APIs to display the created FeatureGroup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e2681d7-ff1b-4c66-a094-440d4cfcc831",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FeatureGroupArn': 'arn:aws:sagemaker:eu-west-1:889960878219:feature-group/rating-fg',\n",
       " 'FeatureGroupName': 'rating-fg',\n",
       " 'RecordIdentifierFeatureName': 'rowID',\n",
       " 'EventTimeFeatureName': 'EventTime',\n",
       " 'FeatureDefinitions': [{'FeatureName': 'rowID', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'timestamp', 'FeatureType': 'String'},\n",
       "  {'FeatureName': 'userID', 'FeatureType': 'String'},\n",
       "  {'FeatureName': 'placeID', 'FeatureType': 'String'},\n",
       "  {'FeatureName': 'rating_overall', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'rating_food', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'rating_service', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'EventTime', 'FeatureType': 'String'}],\n",
       " 'CreationTime': datetime.datetime(2023, 2, 8, 15, 26, 20, 67000, tzinfo=tzlocal()),\n",
       " 'OnlineStoreConfig': {'EnableOnlineStore': True},\n",
       " 'OfflineStoreConfig': {'S3StorageConfig': {'S3Uri': 's3://sagemaker-eu-west-1-889960878219/delta_to_sagemaker/',\n",
       "   'ResolvedOutputS3Uri': 's3://sagemaker-eu-west-1-889960878219/delta_to_sagemaker/889960878219/sagemaker/eu-west-1/offline-store/rating-fg-1675869980/data'},\n",
       "  'DisableGlueTableCreation': False,\n",
       "  'TableFormat': 'Iceberg'},\n",
       " 'RoleArn': 'arn:aws:iam::889960878219:role/service-role/AmazonSageMaker-ExecutionRole-20180920T165537',\n",
       " 'FeatureGroupStatus': 'Creating',\n",
       " 'ResponseMetadata': {'RequestId': 'b7076f36-95f4-4988-bd28-e84324d4c082',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'b7076f36-95f4-4988-bd28-e84324d4c082',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '1572',\n",
       "   'date': 'Wed, 08 Feb 2023 15:26:21 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_group.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce721864-f7e2-4f3f-8a56-0d41caf3bc15",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FeatureGroupSummaries': [{'FeatureGroupName': 'rating-fg',\n",
       "   'FeatureGroupArn': 'arn:aws:sagemaker:eu-west-1:889960878219:feature-group/rating-fg',\n",
       "   'CreationTime': datetime.datetime(2023, 2, 8, 15, 26, 20, 67000, tzinfo=tzlocal()),\n",
       "   'FeatureGroupStatus': 'Creating'}],\n",
       " 'NextToken': 'cIws2QhTXUIa8bi8VaXSkZyCip699fykY7CU0a6rxKatwtimPuAdGzYreBOG3pbaFVlWD8bhEvORr3GSVTKiDoNcR3sdCTEgx3jc4+6Ek0uCkSOvfuULbMXz66iJGu/r8djmlM4jg2iBwnGo9Ht5fKZ8B8sPKtRdVLIdvt9uj13vJlrpbXV7iev8qMBw1FSDkS7unEqe2AN+hESbkUGUWcyHG7cbCNr/pEPQ7QDmirfP8/bzGX38hAv2q5+nr4oAT056IYNnvmlLiZJC3yeMW/ZBkCWM8EDh7con5oWO/Vfa3sH81i1K4n4ef8LhBduIhB1XR8yezoxNij7m6T1etOb2zxX96GpzpMzXixyp1uN+QU5XcixEuvpVk5Zo8u4ghZZ7QF9wyiQBA22n1i8QGyEaaRTDdeDaOsKZw16IvwE8PIIR3Gg0FvzIkYhu8km5rjZ3IWSZ7VtLBlWVkizkdX9NFFRNTB5pVtwX/cy4nrxbWLj2oC9R2IKMz7N/xj0sC7iFaoxHagSki4cyE7ACeWM91U5t42eQwux//4NjT/wrtI4O2xTkM3hMMliTRRGgHtuHKyMDl4QcJnbzEaroNk7lHhwS7HgP0A==',\n",
       " 'ResponseMetadata': {'RequestId': '57187ab4-411f-47a8-9215-049c477e553a',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '57187ab4-411f-47a8-9215-049c477e553a',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '836',\n",
       "   'date': 'Wed, 08 Feb 2023 15:26:21 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_session.boto_session.client(\n",
    "    \"sagemaker\", region_name=region\n",
    ").list_feature_groups(NameContains = 'rating-fg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d84592-644c-460f-8c5d-3a3cf8180226",
   "metadata": {},
   "source": [
    "We can now define our SageMaker Processing job for performing the transformations on our data, and ingesting the results into our Feature Group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01fb1e9e-5780-4d5e-b4fd-ecac9e8723ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.spark.processing import PySparkProcessor\n",
    "\n",
    "spark_processor = PySparkProcessor(\n",
    "    base_job_name=\"delta-to-sagemaker-\",\n",
    "    framework_version=\"3.1\",\n",
    "    role=role,\n",
    "    instance_count=1, #set to >1 for distributed processing\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    max_runtime_in_seconds=1200,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c6990b-7878-4aa0-b9f7-55408caa4e15",
   "metadata": {},
   "source": [
    "We will now create our pre-processing script, including code for reading our Delta Table, performing transformations, and ingesting the resulting features into SageMaker Feature Store.\n",
    "\n",
    "Note in our example we are just including some simple transformations recommended by Data Wrangler on our dataset, but you can replace those with your own transformations if you want to customize this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d53d195-4b0c-4b80-95a4-a25bf27ae43c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./code/preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./code/preprocessing.py\n",
    "import argparse\n",
    "import csv\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "\n",
    "# Import pyspark and build Spark session\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from feature_store_manager import FeatureStoreManager\n",
    "\n",
    "def ingest_to_feature_store(df, feature_group):\n",
    "    # Ingest data to Feature Store using the Feature Store Manager...\n",
    "    print(f\"Ingesting processed features into Feature Group {feature_group}...\")\n",
    "    feature_store_manager = FeatureStoreManager()\n",
    "    feature_store_manager.ingest_data(\n",
    "        input_data_frame=df,\n",
    "        feature_group_arn=f'{feature_group}',\n",
    "        target_stores=['OfflineStore', 'OnlineStore']\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"app inputs and outputs\")\n",
    "    parser.add_argument(\"--region\", type=str, help=\"AWS region\")\n",
    "    parser.add_argument(\"--table\", type=str, help=\"Delta Table URL\")\n",
    "    parser.add_argument(\"--feature-group\", type=str, help=\"Name of the Feature Group\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Instantiate Spark via builder\n",
    "    # Note: we use the `ContainerCredentialsProvider` to give us access to underlying IAM role permissions\n",
    "    spark = (SparkSession\n",
    "        .builder\n",
    "        .appName(\"PySparkApp\") \n",
    "        .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \n",
    "        .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \n",
    "        .config(\"fs.s3a.aws.credentials.provider\",'com.amazonaws.auth.ContainerCredentialsProvider') \n",
    "        .getOrCreate())\n",
    "\n",
    "    sc = spark.sparkContext\n",
    "    print('Spark version: '+str(sc.version))\n",
    "    \n",
    "    s3a_delta_table_uri=args.table\n",
    "    print(s3a_delta_table_uri)\n",
    "\n",
    "    # Create SQL command inserting the S3 path location\n",
    "    sql_cmd = f'SELECT * FROM delta.`{s3a_delta_table_uri}` ORDER BY timestamp'\n",
    "    print(f'SQL command: {sql_cmd}')\n",
    "\n",
    "    # Execute SQL command which returns dataframe\n",
    "    sql_results = spark.sql(sql_cmd)\n",
    "    print(type(sql_results))\n",
    "\n",
    "    # ----------------\n",
    "    # Transformations - Pandas code generated by sagemaker_datawrangler:\n",
    "    processed_features = sql_results.toPandas().copy(deep=True)\n",
    "\n",
    "    # Code to Replace with new value for column: userID to resolve warning: Disguised missing values \n",
    "    generic_value = 'Other'\n",
    "    processed_features['userID']=processed_features['userID'].replace('na', 'Other', regex=False)\n",
    "    processed_features['userID']=processed_features['userID'].replace('nA', 'Other', regex=False)\n",
    "\n",
    "    # Code to Drop column for column: ratingID to resolve warning: ID column \n",
    "    processed_features=processed_features.drop(columns=['ratingID'])\n",
    "    \n",
    "    # Complete with EventTime feature\n",
    "    processed_features['EventTime']=str(pd.to_datetime('now').strftime('%Y-%m-%dT%H:%M:%SZ'))\n",
    "\n",
    "    print(processed_features.head())\n",
    "\n",
    "    # Capture resulting data frame in Spark:\n",
    "    columns = ['rowID', 'timestamp', 'userID', 'placeID', 'rating_overall', 'rating_food', 'rating_service', 'EventTime']\n",
    "    df = spark.createDataFrame(processed_features).toDF(*columns)\n",
    "    # ----------------\n",
    "    \n",
    "    # Ingesting the resulting data into our Feature Group...\n",
    "    ingest_to_feature_store(df, args.feature_group)\n",
    "\n",
    "    print(\"All done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d691e4-2732-47a2-93d0-d06d48d36a75",
   "metadata": {},
   "source": [
    "In our example we are using the SageMaker Spark container as a base, so we will just include the additional \"delta-core\" library as an additional JAR file, together with the \"feature_store_manager\" required for ingesting into the Feature Group at scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac28d794-fae5-4831-b28c-d495e77fd89d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "spark_processor.run(\n",
    "    submit_app='./code/preprocessing.py',\n",
    "    submit_jars=[\n",
    "        './delta-core_2.12-1.0.1.jar',\n",
    "        './feature_store_pyspark/sagemaker-feature-store-spark-sdk.jar'\n",
    "    ],\n",
    "    submit_py_files=[\n",
    "        './feature_store_pyspark/feature_store_manager.py',\n",
    "        './feature_store_pyspark/wrapper.py'\n",
    "    ],\n",
    "    arguments=[\n",
    "        '--region', region,\n",
    "        '--table', table,\n",
    "        '--feature-group', feature_group_arn,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e70997-ed71-460b-9be9-4f5f8edd9adb",
   "metadata": {},
   "source": [
    "(Note we omit the output for brevity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab7b739-0635-462c-91e9-29af444969e1",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Verifying processed data in SageMaker Feature Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9969ae12-c3eb-43a7-aa87-6680f0214ef2",
   "metadata": {},
   "source": [
    "#### Reading from the Online Store\n",
    "\n",
    "Using an arbirary row ID 5, we use `get_record` to check that the data has been ingested into the feature group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "79add55b-9b20-4b5e-83a3-c3074a62aec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_record = sm_session.boto_session.client(\n",
    "    \"sagemaker-featurestore-runtime\", region_name=region\n",
    ").get_record(\n",
    "    FeatureGroupName=feature_group_name,\n",
    "    RecordIdentifierValueAsString='5'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2f690e33-2caf-4df3-bd65-453d22c94254",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '76757183-1565-4434-8203-527d81d2d301',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '76757183-1565-4434-8203-527d81d2d301',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '430',\n",
       "   'date': 'Wed, 08 Feb 2023 16:12:52 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Record': [{'FeatureName': 'rowID', 'ValueAsString': '5'},\n",
       "  {'FeatureName': 'timestamp', 'ValueAsString': '2022-08-25'},\n",
       "  {'FeatureName': 'userID', 'ValueAsString': 'gK'},\n",
       "  {'FeatureName': 'placeID', 'ValueAsString': '585'},\n",
       "  {'FeatureName': 'rating_overall', 'ValueAsString': '1'},\n",
       "  {'FeatureName': 'rating_food', 'ValueAsString': '0'},\n",
       "  {'FeatureName': 'rating_service', 'ValueAsString': '0'},\n",
       "  {'FeatureName': 'EventTime', 'ValueAsString': '2023-02-08T15:31:31Z'}]}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cec1dc-5dd7-47b6-8a9a-4f71cef9c960",
   "metadata": {},
   "source": [
    "We can also use `batch_get_record` to check multiple records ingested into the feature groups by providing customer ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18b0bf53-2495-4316-a0d1-18888785c040",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_records = sm_session.boto_session.client(\n",
    "    'sagemaker-featurestore-runtime', region_name=region\n",
    ").batch_get_record(\n",
    "    Identifiers=[\n",
    "        {\n",
    "            'FeatureGroupName': feature_group_name,\n",
    "            'RecordIdentifiersValueAsString': ['5', '3', '8'],\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a9eede3-069c-4c58-8d45-598163928106",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'cb92a780-dc5f-4a39-bed0-aa843d86ec5d',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'cb92a780-dc5f-4a39-bed0-aa843d86ec5d',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '1549',\n",
       "   'date': 'Wed, 08 Feb 2023 15:32:55 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Records': [{'FeatureGroupName': 'rating-fg',\n",
       "   'RecordIdentifierValueAsString': '3',\n",
       "   'Record': [{'FeatureName': 'rowID', 'ValueAsString': '3'},\n",
       "    {'FeatureName': 'timestamp', 'ValueAsString': '2022-08-25'},\n",
       "    {'FeatureName': 'userID', 'ValueAsString': 'gK'},\n",
       "    {'FeatureName': 'placeID', 'ValueAsString': '1203'},\n",
       "    {'FeatureName': 'rating_overall', 'ValueAsString': '1'},\n",
       "    {'FeatureName': 'rating_food', 'ValueAsString': '2'},\n",
       "    {'FeatureName': 'rating_service', 'ValueAsString': '2'},\n",
       "    {'FeatureName': 'EventTime', 'ValueAsString': '2023-02-08T15:31:31Z'}]},\n",
       "  {'FeatureGroupName': 'rating-fg',\n",
       "   'RecordIdentifierValueAsString': '8',\n",
       "   'Record': [{'FeatureName': 'rowID', 'ValueAsString': '8'},\n",
       "    {'FeatureName': 'timestamp', 'ValueAsString': '2022-08-25'},\n",
       "    {'FeatureName': 'userID', 'ValueAsString': 'gL'},\n",
       "    {'FeatureName': 'placeID', 'ValueAsString': '1390'},\n",
       "    {'FeatureName': 'rating_overall', 'ValueAsString': '2'},\n",
       "    {'FeatureName': 'rating_food', 'ValueAsString': '2'},\n",
       "    {'FeatureName': 'rating_service', 'ValueAsString': '2'},\n",
       "    {'FeatureName': 'EventTime', 'ValueAsString': '2023-02-08T15:31:31Z'}]},\n",
       "  {'FeatureGroupName': 'rating-fg',\n",
       "   'RecordIdentifierValueAsString': '5',\n",
       "   'Record': [{'FeatureName': 'rowID', 'ValueAsString': '5'},\n",
       "    {'FeatureName': 'timestamp', 'ValueAsString': '2022-08-25'},\n",
       "    {'FeatureName': 'userID', 'ValueAsString': 'gK'},\n",
       "    {'FeatureName': 'placeID', 'ValueAsString': '585'},\n",
       "    {'FeatureName': 'rating_overall', 'ValueAsString': '1'},\n",
       "    {'FeatureName': 'rating_food', 'ValueAsString': '0'},\n",
       "    {'FeatureName': 'rating_service', 'ValueAsString': '0'},\n",
       "    {'FeatureName': 'EventTime', 'ValueAsString': '2023-02-08T15:31:31Z'}]}],\n",
       " 'Errors': [],\n",
       " 'UnprocessedIdentifiers': []}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0d8abb-205f-4ea3-a747-703b248d7323",
   "metadata": {},
   "source": [
    "#### Reading from the Offline Store\n",
    "\n",
    "We will now use the built-in Athena query capabilities in the Feature Store, for running a query towards our Offline Store.\n",
    "\n",
    "Note the offline store is in Amazon S3 and having the records stored in Apache Iceberg format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7087a50-4db0-447d-8db6-f0aa7d38cb06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rating_fg = FeatureGroup(name=feature_group_name, sagemaker_session=sm_session)  \n",
    "rating_query = rating_fg.athena_query()\n",
    "rating_table = rating_query.table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "35848e60-d26c-411f-9528-519fe01abe0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT * FROM \"rating-fg-1675869980\"WHERE \"rating-fg-1675869980\".\"userid\" = \\'gL\\''"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_string = f'SELECT * FROM \"{rating_table}\"' \\\n",
    "               f'WHERE \"{rating_table}\".\"userid\" = \\'gL\\''\n",
    "query_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "325fc1f6-cb42-48c8-aa3d-df518889b4f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Athena query output location: \n",
      "s3://sagemaker-eu-west-1-889960878219/delta_to_sagemaker/query_results/\n"
     ]
    }
   ],
   "source": [
    "output_location = f's3://{bucket}/delta_to_sagemaker/query_results/'\n",
    "print(f'Athena query output location: \\n{output_location}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3a4d2add-4713-4cab-ab19-0770b3bc694c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Query eabedb04-8eb8-4092-9b8f-93f162e51e6e is being executed.\n",
      "INFO:sagemaker:Query eabedb04-8eb8-4092-9b8f-93f162e51e6e successfully executed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>write_time</th>\n",
       "      <th>api_invocation_time</th>\n",
       "      <th>is_deleted</th>\n",
       "      <th>rowid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>userid</th>\n",
       "      <th>placeid</th>\n",
       "      <th>rating_overall</th>\n",
       "      <th>rating_food</th>\n",
       "      <th>rating_service</th>\n",
       "      <th>eventtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-08 15:36:45.230 UTC</td>\n",
       "      <td>2023-02-08 15:31:42.000 UTC</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>2022-08-25</td>\n",
       "      <td>gL</td>\n",
       "      <td>427</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-08T15:31:31Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-08 15:36:43.261 UTC</td>\n",
       "      <td>2023-02-08 15:31:42.000 UTC</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>2022-08-25</td>\n",
       "      <td>gL</td>\n",
       "      <td>1390</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-08T15:31:31Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-08 15:36:43.274 UTC</td>\n",
       "      <td>2023-02-08 15:31:42.000 UTC</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-08-25</td>\n",
       "      <td>gL</td>\n",
       "      <td>990</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-08T15:31:31Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-08 15:36:43.235 UTC</td>\n",
       "      <td>2023-02-08 15:31:42.000 UTC</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-08-25</td>\n",
       "      <td>gL</td>\n",
       "      <td>1192</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-08T15:31:31Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-08 15:36:43.235 UTC</td>\n",
       "      <td>2023-02-08 15:31:42.000 UTC</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>2022-08-25</td>\n",
       "      <td>gL</td>\n",
       "      <td>486</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-08T15:31:31Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-02-08 15:36:43.303 UTC</td>\n",
       "      <td>2023-02-08 15:31:42.000 UTC</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>2022-08-25</td>\n",
       "      <td>gL</td>\n",
       "      <td>682</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-08T15:31:31Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-02-08 15:36:43.222 UTC</td>\n",
       "      <td>2023-02-08 15:31:42.000 UTC</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>2022-08-25</td>\n",
       "      <td>gL</td>\n",
       "      <td>1052</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-08T15:31:31Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    write_time          api_invocation_time  is_deleted  \\\n",
       "0  2023-02-08 15:36:45.230 UTC  2023-02-08 15:31:42.000 UTC       False   \n",
       "1  2023-02-08 15:36:43.261 UTC  2023-02-08 15:31:42.000 UTC       False   \n",
       "2  2023-02-08 15:36:43.274 UTC  2023-02-08 15:31:42.000 UTC       False   \n",
       "3  2023-02-08 15:36:43.235 UTC  2023-02-08 15:31:42.000 UTC       False   \n",
       "4  2023-02-08 15:36:43.235 UTC  2023-02-08 15:31:42.000 UTC       False   \n",
       "5  2023-02-08 15:36:43.303 UTC  2023-02-08 15:31:42.000 UTC       False   \n",
       "6  2023-02-08 15:36:43.222 UTC  2023-02-08 15:31:42.000 UTC       False   \n",
       "\n",
       "   rowid   timestamp userid  placeid  rating_overall  rating_food  \\\n",
       "0     12  2022-08-25     gL      427               2            2   \n",
       "1      8  2022-08-25     gL     1390               2            2   \n",
       "2      6  2022-08-25     gL      990               2            2   \n",
       "3      7  2022-08-25     gL     1192               2            2   \n",
       "4     11  2022-08-25     gL      486               2            2   \n",
       "5     10  2022-08-25     gL      682               2            2   \n",
       "6      9  2022-08-25     gL     1052               2            2   \n",
       "\n",
       "   rating_service             eventtime  \n",
       "0               2  2023-02-08T15:31:31Z  \n",
       "1               2  2023-02-08T15:31:31Z  \n",
       "2               2  2023-02-08T15:31:31Z  \n",
       "3               2  2023-02-08T15:31:31Z  \n",
       "4               2  2023-02-08T15:31:31Z  \n",
       "5               2  2023-02-08T15:31:31Z  \n",
       "6               2  2023-02-08T15:31:31Z  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_query.run(query_string=query_string, output_location=output_location)\n",
    "rating_query.wait()\n",
    "joined_df = rating_query.as_dataframe()\n",
    "joined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f7bbeb-ed29-4980-8c2e-17329f1a4ffc",
   "metadata": {},
   "source": [
    "----------\n",
    "\n",
    "### (Optional) Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bfef18-5e32-4a67-890d-97427c5c0747",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Delete the feature group\n",
    "!aws sagemaker delete-feature-group --feature-group-name rating-fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef08b66-206e-4e52-816b-109e3939b6be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Delete the copy of the processed data in S3\n",
    "!aws s3 rm --recursive s3://{bucket}/delta_to_sagemaker/processing_output/processed_features.csv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87df4856-5049-4a3e-b209-c5e2b41996d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
